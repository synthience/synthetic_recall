classDiagram
    %% Core State Management
    class VoiceStateManager {
        -_state: VoiceState
        -_state_lock: asyncio.Lock
        -_event_handlers: dict
        -_room: rtc.Room
        -_tts_track: rtc.LocalAudioTrack
        -_tts_source: rtc.AudioSource
        +current_state: VoiceState
        +set_state(new_state: VoiceState)
        +set_room(room: rtc.Room)
        +on(event_name: str, handler: Callable)
        +emit(event_name: str, data: Any)
        +transition_to(new_state: VoiceState, metadata: dict)
        +handle_user_speech_detected(text: str)
        +handle_user_transcript(text: str)
        +publish_transcript(text: str, is_user: bool)
        +handle_stt_transcript(text: str)
        +setup_tts_track(room: rtc.Room)
        +handle_assistant_response(text: str)
        +start_speaking(tts_task: asyncio.Task)
        +cleanup_tts_track()
        +start_listening()
        +register_error(error: Exception, source: str)
        +interrupt_requested(): bool
        +wait_for_interrupt(timeout: float): bool
    }

    %% Voice State Enumeration
    class VoiceState {
        <<enumeration>>
        IDLE
        LISTENING
        SPEAKING
        PROCESSING
        INTERRUPTED
        ERROR
    }

    %% Speech-to-Text Service
    class EnhancedSTTService {
        -state_manager: VoiceStateManager
        -vosk_model_name: str
        -whisper_model_name: str
        -device: str
        -min_speech_duration: float
        -max_speech_duration: float
        -energy_threshold: float
        -on_transcript: Callable
        -whisper_model
        -vosk_model
        -vosk_recognizer
        -sample_rate: int
        -buffer: list
        -buffer_duration: float
        -is_speaking: bool
        -speech_start_time: float
        -last_speech_time: float
        -speech_duration: float
        -silence_duration: float
        -silence_start_time: float
        -executor: ThreadPoolExecutor
        -room: rtc.Room
        -last_transcript: str
        -last_partial: str
        +initialize()
        +set_room(room: rtc.Room)
        +process_audio(track: rtc.AudioTrack)
        +_find_vosk_model_path(): str
        +_process_audio_buffer(audio_data: np.ndarray): str
        +_finalize_transcript(): str
        +_whisper_transcribe(audio_array: np.ndarray): dict
        +cleanup()
        +get_stats(): dict
    }

    %% Text-to-Speech Service
    class InterruptibleTTSService {
        -state_manager: VoiceStateManager
        -voice: str
        -sample_rate: int
        -num_channels: int
        -on_interrupt: Callable
        -on_complete: Callable
        -room: rtc.Room
        -_active: bool
        -_cancellable: bool
        -_current_task: asyncio.Task
        -_playback_lock: asyncio.Lock
        +initialize()
        +set_room(room: rtc.Room)
        +speak(text: str): bool
        +_stream_tts(text: str): bool
        +_convert_mp3_to_pcm(mp3_data: bytes): tuple
        +stop()
        +cleanup()
    }

    %% LLM Integration
    class LocalLLMPipeline {
        -config: LLMConfig
        -session: aiohttp.ClientSession
        -base_url: str
        +initialize()
        +generate_response(prompt: str, conversation_history: list, system_message: str): str
        +cleanup()
        +close()
    }

    %% Voice Pipeline Agent
    class LucidiaVoiceAgent {
        -job_context: JobContext
        -room: rtc.Room
        -initial_greeting: str
        -session_id: str
        -state_manager: VoiceStateManager
        -config: LucidiaConfig
        -llm_config: LLMConfig
        -stt_service: EnhancedSTTService
        -tts_service: InterruptibleTTSService
        -llm_service: LocalLLMPipeline
        -_initialized: bool
        -_running: bool
        -_shutdown_requested: bool
        -_heartbeat_task: asyncio.Task
        -conversation_history: list
        +initialize()
        +_connection_heartbeat()
        +start()
        +_publish_ui_update(data: dict): bool
        +publish_assistant_transcript(text: str)
        +_handle_transcript(text: str)
        +_get_context(): dict
        +process_audio(track: rtc.AudioTrack)
        +cleanup()
    }

    %% Config Classes
    class LucidiaConfig {
        +sample_rate: int
        +channels: int
        +chunk_size: int
        +buffer_size: int
    }

    class LLMConfig {
        +model: str
        +api_endpoint: str
        +temperature: float
        +max_tokens: int
        +top_p: float
        +stream: bool
    }

    %% Audio Processing
    class AudioBuffer {
        +buffer: io.BytesIO
        +max_size: int
        +last_speech: bool
        +speech_start: float
        +silence_duration: float
        +is_speaking: bool
        +add_frame(frame_data: bytes)
        +get_data(): bytes
        +clear()
    }

    %% LiveKit Integration
    class LiveKitTTSService {
        -config: LucidiaConfig
        -audio_queue: asyncio.Queue
        -_shutdown: bool
        -_queue_task: asyncio.Task
        -room: rtc.Room
        -audio_source: rtc.AudioSource
        -local_track: rtc.LocalAudioTrack
        -_running: bool
        -session_id: str
        -_event_handlers: dict
        -stats: dict
        +on(event: str, callback: Callable)
        +connect(room: rtc.Room)
        +synthesize_speech(text: str, interrupt: bool)
        +_queue_audio_chunks(audio_data: bytes)
        +_process_audio_queue()
        +stop_speaking()
        +is_speaking(): bool
        +cleanup()
    }

    %% Relationships
    VoiceStateManager --> VoiceState : uses
    EnhancedSTTService --> VoiceStateManager : uses
    InterruptibleTTSService --> VoiceStateManager : uses
    LucidiaVoiceAgent *-- VoiceStateManager : contains
    LucidiaVoiceAgent *-- EnhancedSTTService : contains
    LucidiaVoiceAgent *-- InterruptibleTTSService : contains
    LucidiaVoiceAgent *-- LocalLLMPipeline : contains
    LucidiaVoiceAgent --> LucidiaConfig : uses
    LucidiaVoiceAgent --> LLMConfig : uses
    LocalLLMPipeline --> LLMConfig : uses
    LiveKitTTSService --> LucidiaConfig : uses
    InterruptibleTTSService ..> AudioBuffer : may use
