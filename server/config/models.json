{
  "models": {
    "qwen2.5-7b-instruct": {
      "purposes": [
        "general",
        "reasoning",
        "creative"
      ],
      "context_length": 8192,
      "strength": 0.8,
      "speed": 0.7,
      "resource_usage": {
        "memory": 0.7,
        "cpu": 0.7
      }
    },
    "phi3.5-mini": {
      "purposes": [
        "general",
        "memory",
        "reflection"
      ],
      "context_length": 4096,
      "strength": 0.6,
      "speed": 0.9,
      "resource_usage": {
        "memory": 0.3,
        "cpu": 0.3
      }
    },
    "gemma2-9b-it": {
      "purposes": [
        "reasoning",
        "analysis",
        "dreaming"
      ],
      "context_length": 8192,
      "strength": 0.85,
      "speed": 0.6,
      "resource_usage": {
        "memory": 0.8,
        "cpu": 0.8
      }
    },
    "mistral-nemo": {
      "purposes": [
        "creative",
        "dreaming",
        "reflection"
      ],
      "context_length": 16384,
      "strength": 0.9,
      "speed": 0.5,
      "resource_usage": {
        "memory": 0.9,
        "cpu": 0.9
      }
    },
    "all-MiniLM-L6-v2": {
      "purposes": [
        "embedding"
      ],
      "context_length": 512,
      "strength": 0.7,
      "speed": 0.95,
      "resource_usage": {
        "memory": 0.2,
        "cpu": 0.2
      }
    }
  },
  "default_model": "qwen2.5-7b-instruct",
  "parameters": {
    "switch_cooldown": 60
  }
}